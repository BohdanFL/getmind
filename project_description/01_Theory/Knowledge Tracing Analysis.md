### 1. Bayesian Knowledge Tracing (BKT)
**Суть:** Це прихована марковська модель (Hidden Markov Model). Вона припускає, що знання — це «прихована» бінарна змінна: ти або **знаєш** тему (Mastery), або **ні**.

**Параметри (класичні):**
1.  **$P(L_0)$ (Initial Knowledge):** ймовірність того, що учень знає тему до початку.
2.  **$P(T)$ (Transition):** ймовірність того, що після одного кроку навчання учень перейде з невігластва до знання.
3.  **$P(G)$ (Guess):** ймовірність вгадати правильно, не знаючи теми.
4.  **$P(S)$ (Slip):** ймовірність помилитися, навіть якщо ти знаєш тему.

**Плюси:**
*   **Інтерпретованість:** Ти чітко бачиш, на якому етапі учень.
*   **Mastery Learning:** Алгоритм прямо каже, коли можна припинити давати завдання (коли ймовірність знання > 0.95).

**Мінуси:**
*   **Бінарність:** Він не враховує «часткове знання».
*   **Атомарність:** Важко відстежувати взаємозв'язки між різними темами.

---

### 2. Performance Factors Analysis (PFA)
Це головний конкурент BKT. Замість імовірнісних мереж він використовує **логістичну регресію**.

**Формула (спрощено):**
Шанс на успіх залежить від: (Складність теми) + (Кількість попередніх успіхів) + (Кількість попередніх помилок).

**Плюси:**
*   **Чутливість до практики:** Він враховує кожен успіх і кожну невдачу окремо.
*   **Мульти-скіл:** Легко працює, коли одне завдання вимагає знання двох різних тем одночасно.
*   **Точність:** Дослідження показують, що PFA часто краще пророкує майбутні відповіді учня, ніж BKT.

**Мінуси:**
*   Він не каже прямо «учень вивчив це». Він каже «шанс успіху високий».

---

### 3. Item Response Theory (IRT)
Класика психометрики (використовується в GRE, GMAT, ЗНО).

**Суть:** Оцінює два параметри одночасно:
1.  **Ability ($\theta$):** Справжній рівень здібностей учня.
2.  **Difficulty ($\beta$):** Справжня складність питання.

**Застосування:** Якщо учень відповів на дуже складне питання, його рейтинг здібностей злітає вгору набагато сильніше, ніж за відповідь на просте.

---

### 4. Deep Knowledge Tracing (DKT)
Це «модний» підхід з використанням нейронних мереж (RNN/LSTM/Transformers).

*   **Як працює:** Нейронка отримує на вхід всю історію відповідей учня і передбачає ймовірність правильної відповіді на наступне питання.
*   **Проблема для диплома:** Це «чорна скринька». Ти не зможеш легко пояснити, чому вона так вирішила. Потрібно дуже багато даних (тисячі учнів), яких у тебе не буде.

---

### Порівняльна таблиця для твого аналізу:

| Алгоритм | Модель | Перевага | Недолік | Для твого проєкту |
| :--- | :--- | :--- | :--- | :--- |
| **BKT** | Hidden Markov Model | Чітке поняття "Mastery" | Знання або є, або немає | **Ідеально для основної логіки** |
| **PFA** | Logistic Regression | Чутливість до кількості повторів | Важче інтерпретувати стан знань | Можна використати для Project Lab |
| **IRT** | Psychometric Model | Враховує складність питань | Зазвичай вважає, що знання статичні | Корисно для оцінки складності PDF |
| **DKT** | Neural Networks (RNN) | Максимальна точність прогнозу | Потрібні Big Data, немає прозорості | Не рекомендую для соло-MVP |

---

### Що я рекомендую для твого проєкту (CogniFlow Strategy):

Для диплома найкраще обрати **Гібридний підхід**. Це покаже, що ти провів глибокий аналіз.

1.  **Використовуй BKT як базу:** Оскільки твоя мета — "Make It Stick" (довготривале знання), тобі важливо знати, чи досягнута точка "Mastery".
2.  **Додай елемент IRT:** Оскільки ти використовуєш ШІ для генерації питань, ти можеш попросити ШІ самому оцінити складність питання, яке він згенерував. Ця складність буде впливати на те, наскільки сильно зміниться рейтинг учня за BKT.

#### Чому BKT краще для тебе в контексті ШІ:
Твій проект базується на LLM. Коли ШІ оцінює відповідь користувача (Semantic Grading), він видає не просто "правильно/неправильно", а може видати "ступінь правильності" (наприклад, 0.7).
*   У класичному BKT відповідь бінарна (0 або 1).
*   У своєму проєкті ти можеш реалізувати **"Soft-BKT"**, де ймовірність знання оновлюється пропорційно до балу, який поставив ШІ. **Це твоя унікальна наукова фішка.**

### Як це описати в дипломі:
Ти можеш написати підрозділ: *«Модифікація класичної моделі Bayesian Knowledge Tracing для роботи з нечіткими оцінками генеративного ШІ»*.